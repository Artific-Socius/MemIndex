@inproceedings{petroni2021kilt_LR,
  title={KILT: a benchmark for knowledge intensive language tasks},
  author={Petroni, Fabio and Piktus, Aleksandra and Fan, Angela and Lewis, Patrick and Yazdani, Majid and De Cao, Nicola and Thorne, James and Jernite, Yacine and Karpukhin, Vladimir and Maillard, Jean and others},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={2523--2544},
  year={2021}
}

@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM computing surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}


@article{salehin2025systematic,
  title={Systematic Literature Review of LLM-Large Language Model in Medical: Digital Health, Technology and Applications},
  author={Salehin, Imrus and Tomal Ahmed Sajib, Md and Huda Badhon, Nazmul and Sakibul Hassan Rifat, Md and Amin, Nazrul and Nessa Moon, Nazmun},
  journal={Engineering Reports},
  volume={7},
  number={9},
  pages={e70365},
  year={2025},
  publisher={Wiley Online Library}
}

@inproceedings{li2023large,
  title={Large language models in finance: A survey},
  author={Li, Yinheng and Wang, Shaofei and Ding, Han and Chen, Hang},
  booktitle={Proceedings of the fourth ACM international conference on AI in finance},
  pages={374--382},
  year={2023}
}

@article{shool2025systematic,
  title={A systematic review of large language model (LLM) evaluations in clinical medicine},
  author={Shool, Sina and Adimi, Sara and Saboori Amleshi, Reza and Bitaraf, Ehsan and Golpira, Reza and Tara, Mahmood},
  journal={BMC Medical Informatics and Decision Making},
  volume={25},
  number={1},
  pages={117},
  year={2025},
  publisher={Springer}
}

@inproceedings{yu2025survey,
  title={A survey on trustworthy llm agents: Threats and countermeasures},
  author={Yu, Miao and Meng, Fanci and Zhou, Xinyun and Wang, Shilong and Mao, Junyuan and Pan, Linsey and Chen, Tianlong and Wang, Kun and Li, Xinfeng and Zhang, Yongfeng and others},
  booktitle={Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V. 2},
  pages={6216--6226},
  year={2025}
}

@article{shen2024llm,
  title={Llm with tools: A survey},
  author={Shen, Zhuocheng},
  journal={arXiv preprint arXiv:2409.18807},
  year={2024}
}

@inproceedings{zhou2024llm,
  title={Is LLM a reliable reviewer? a comprehensive evaluation of LLM on automatic paper reviewing tasks},
  author={Zhou, Ruiyang and Chen, Lu and Yu, Kai},
  booktitle={Proceedings of the 2024 joint international conference on computational linguistics, language resources and evaluation (LREC-COLING 2024)},
  pages={9340--9351},
  year={2024}
}

@inproceedings{lee2025evaluating,
  title={Evaluating the consistency of llm evaluators},
  author={Lee, Noah and Hong, Jiwoo and Thorne, James},
  booktitle={Proceedings of the 31st International Conference on Computational Linguistics},
  pages={10650--10659},
  year={2025}
}

@article{zhou2023don,
  title={Don't make your llm an evaluation benchmark cheater},
  author={Zhou, Kun and Zhu, Yutao and Chen, Zhipeng and Chen, Wentong and Zhao, Wayne Xin and Chen, Xu and Lin, Yankai and Wen, Ji-Rong and Han, Jiawei},
  journal={arXiv preprint arXiv:2311.01964},
  year={2023}
}

@inproceedings{mohammadi2025evaluation,
  title={Evaluation and benchmarking of llm agents: A survey},
  author={Mohammadi, Mahmoud and Li, Yipeng and Lo, Jane and Yip, Wendy},
  booktitle={Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V. 2},
  pages={6129--6139},
  year={2025}
}

@article{vendrow2025large,
  title={Do large language model benchmarks test reliability?},
  author={Vendrow, Joshua and Vendrow, Edward and Beery, Sara and Madry, Aleksander},
  journal={arXiv preprint arXiv:2502.03461},
  year={2025}
}

@article{perlitz2024these,
  title={Do these llm benchmarks agree? fixing benchmark evaluation with benchbench},
  author={Perlitz, Yotam and Gera, Ariel and Arviv, Ofir and Yehudai, Asaf and Bandel, Elron and Shnarch, Eyal and Shmueli-Scheuer, Michal and Choshen, Leshem},
  journal={arXiv preprint arXiv:2407.13696},
  year={2024}
}

@article{yuan2025llm,
  title={Llm-powered benchmark factory: Reliable, generic, and efficient},
  author={Yuan, Peiwen and Feng, Shaoxiong and Li, Yiwei and Wang, Xinglin and Zhang, Yueqi and Shi, Jiayi and Tan, Chuyi and Pan, Boyuan and Hu, Yao and Li, Kan},
  journal={arXiv preprint arXiv:2502.01683},
  year={2025}
}

@inproceedings{vendrow2024large,
  title={Large language model benchmarks do not test reliability},
  author={Vendrow, Joshua and Vendrow, Edward and Beery, Sara and Madry, Aleksander},
  booktitle={Neurips Safe Generative AI Workshop 2024},
  year={2024}
}

@article{havrilla2024understanding,
  title={Understanding the effect of noise in llm training data with algorithmic chains of thought},
  author={Havrilla, Alex and Iyer, Maia},
  journal={arXiv preprint arXiv:2402.04004},
  year={2024}
}

@article{atil2024llm,
  title={LLM Stability: A detailed analysis with some surprises},
  author={Atil, Berk and Chittams, Alexa and Fu, Liseng and Ture, Ferhan and Xu, Lixinyu and Baldwin, Breck},
  journal={arXiv e-prints},
  pages={arXiv--2408},
  year={2024}
}

@article{banerjee2024vulnerability,
  title={The Vulnerability of Language Model Benchmarks: Do They Accurately Reflect True LLM Performance?},
  author={Banerjee, Sourav and Agarwal, Ayushi and Singh, Eishkaran},
  journal={arXiv preprint arXiv:2412.03597},
  year={2024}
}


@article{ye2024benchmarking,
  title={Benchmarking llms via uncertainty quantification},
  author={Ye, Fanghua and Yang, Mingming and Pang, Jianhui and Wang, Longyue and Wong, Derek and Yilmaz, Emine and Shi, Shuming and Tu, Zhaopeng},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={15356--15385},
  year={2024}
}

@article{yadkori2024believe,
  title={To believe or not to believe your llm},
  author={Yadkori, Yasin Abbasi and Kuzborskij, Ilja and Gy{\"o}rgy, Andr{\'a}s and Szepesv{\'a}ri, Csaba},
  journal={arXiv preprint arXiv:2406.02543},
  year={2024}
}

@article{perlitz2024these,
  title={Do these llm benchmarks agree? fixing benchmark evaluation with benchbench},
  author={Perlitz, Yotam and Gera, Ariel and Arviv, Ofir and Yehudai, Asaf and Bandel, Elron and Shnarch, Eyal and Shmueli-Scheuer, Michal and Choshen, Leshem},
  journal={arXiv preprint arXiv:2407.13696},
  year={2024}
}